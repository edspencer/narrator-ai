"use strict";(self.webpackChunkdocs_2=self.webpackChunkdocs_2||[]).push([[873],{2163:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var o=t(4848),a=t(8453);const r={sidebar_position:5,title:"Configuration"},i="Configuration",s={id:"configuration",title:"Configuration",description:"All of the configurations for Narrator are optional, but you can significantly influence its operation by passing some or all of the following:",source:"@site/docs/configuration.md",sourceDirName:".",slug:"/configuration",permalink:"/narrator-ai/configuration",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5,title:"Configuration"},sidebar:"docs",previous:{title:"Training Narrator",permalink:"/narrator-ai/training"},next:{title:"Narrator",permalink:"/narrator-ai/api/classes/Narrator"}},l={},d=[{value:"Generation Options",id:"generation-options",level:3},{value:"Example Saving Options",id:"example-saving-options",level:3}];function c(e){const n={code:"code",h1:"h1",h3:"h3",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"configuration",children:"Configuration"})}),"\n",(0,o.jsx)(n.p,{children:"All of the configurations for Narrator are optional, but you can significantly influence its operation by passing some or all of the following:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'export const narrator = new Narrator({\n  //lets you specify the output filename for a given docId\n  outputFilename: (docId) => `${docId}.md`,\n\n  //directory where generated content will be saved (nested under the docId)\n  outputDir: path.join(process.cwd(), "editorial"),\n\n  //directory where examples of good/bad content will be saved (in .yml files)\n  examplesDir: path.join(process.cwd(), "editorial", "examples"),\n\n  //provide your own model (using Vercel AI SDK)\n  model: openai("gpt-4o-mini"),\n\n  //if you want to set the temperature (defaults to 0.9)\n  temperature: 0.7,\n\n  //if you want to pass in your own winston logger instance\n  logger: myCustomWinstonLogger,\n\n  //you probably won\'t do this, just lets you pass in a different class to evaluate during training\n  //check out Trainer.ts if this interests you\n  trainer: myTrainer,\n\n  //if you want to change how the examples are presented to the LLM\n  exampleTemplate: ({ verdict, content }) => `This content was marked as ${verdict}: ${content}`,\n});\n'})}),"\n",(0,o.jsx)(n.h3,{id:"generation-options",children:"Generation Options"}),"\n",(0,o.jsxs)(n.p,{children:["As well as the ",(0,o.jsx)(n.code,{children:"GenerationTask"}),", you can pass in some options when generating:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'const docId = "tag/ai";\nconst prompt = "Generate some intro text for blah blah blah...";\n\nnarrator.generate(\n  { docId, prompt },\n  {\n    //to save the generated content (defaults to false)\n    save: true,\n\n    //to return a text stream object instead of a string response (defaults to false)\n    stream: true,\n\n    //if you want to use a different model for this generation\n    model: openai("gpt-4o-mini"),\n\n    //if you want to use a different temperature for this generation\n    temperature: 0.3,\n\n    //to change the default limit of good examples passed to the LLM (defaults to 5)\n    goodExamplesLimit: 10,\n\n    //to change the default limit of bad examples passed to the LLM (defaults to 5)\n    badExamplesLimit: 10,\n  }\n);\n'})}),"\n",(0,o.jsx)(n.p,{children:"If you have more good/bad examples than the limits allow, Narrator will randomly select as many as you asked for."}),"\n",(0,o.jsx)(n.h3,{id:"example-saving-options",children:"Example Saving Options"}),"\n",(0,o.jsxs)(n.p,{children:["When saving some content as a good/bad example, you can pass in the following (",(0,o.jsx)(n.code,{children:"docId"})," and ",(0,o.jsx)(n.code,{children:"verdict"})," are required):"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'narrator.saveExample({\n  docId: "tag/ai",\n\n  //could also be \'bad\'...\n  verdict: "good",\n\n  //optional, but recommended\n  reason: "it has that certain je ne sais quoi",\n\n  //optional, but if you don\'t pass it in then Narrator will try to retrieve it based on docId\n  content: "If you don\'t provide this yourself, Narrator will try to find it",\n});\n'})})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>s});var o=t(6540);const a={},r=o.createContext(a);function i(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);